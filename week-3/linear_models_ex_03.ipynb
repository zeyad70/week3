{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Exercise M4.03\n",
    "\n",
    "Now, we tackle a (relatively) realistic classification problem instead of making\n",
    "a synthetic dataset. We start by loading the Adult Census dataset with the\n",
    "following snippet. For the moment we retain only the **numerical features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  capital-gain  capital-loss  hours-per-week\n",
       "0       25             0             0              40\n",
       "1       38             0             0              50\n",
       "2       28             0             0              40\n",
       "3       44          7688             0              40\n",
       "4       18             0             0              30\n",
       "...    ...           ...           ...             ...\n",
       "48837   27             0             0              38\n",
       "48838   40             0             0              40\n",
       "48839   58             0             0              40\n",
       "48840   22             0             0              20\n",
       "48841   52         15024             0              40\n",
       "\n",
       "[48842 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"./datasets/adult-census.csv\")\n",
    "target = adult_census[\"class\"]\n",
    "data = adult_census.select_dtypes([\"integer\", \"floating\"])\n",
    "data = data.drop(columns=[\"education-num\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm that all the selected features are numerical.\n",
    "\n",
    "Define a linear model composed of a `StandardScaler` followed by a\n",
    "`LogisticRegression` with default parameters.\n",
    "\n",
    "Then use a 10-fold cross-validation to estimate its generalization performance\n",
    "in terms of accuracy. Also set `return_estimator=True` to be able to inspect\n",
    "the trained estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.08813834, 0.07645988, 0.08178067, 0.06988859, 0.07616735,\n",
       "        0.08037972, 0.07894349, 0.07988119, 0.07268715, 0.06772637]),\n",
       " 'score_time': array([0.0063858 , 0.00673103, 0.00704527, 0.01048279, 0.01148915,\n",
       "        0.00823236, 0.00732422, 0.00851059, 0.00210357, 0.00981236]),\n",
       " 'estimator': [Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                  ('logisticregression', LogisticRegression())]),\n",
       "  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                  ('logisticregression', LogisticRegression())]),\n",
       "  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                  ('logisticregression', LogisticRegression())]),\n",
       "  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                  ('logisticregression', LogisticRegression())]),\n",
       "  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                  ('logisticregression', LogisticRegression())]),\n",
       "  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                  ('logisticregression', LogisticRegression())]),\n",
       "  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                  ('logisticregression', LogisticRegression())]),\n",
       "  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                  ('logisticregression', LogisticRegression())]),\n",
       "  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                  ('logisticregression', LogisticRegression())]),\n",
       "  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                  ('logisticregression', LogisticRegression())])],\n",
       " 'test_score': array([0.79856704, 0.79283521, 0.79668305, 0.80487305, 0.80036855,\n",
       "        0.79914005, 0.79750205, 0.7993448 , 0.80528256, 0.80405405])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "numerical_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=100)\n",
    ")\n",
    "\n",
    "cv_results_num = cross_validate(\n",
    "    numerical_pipeline, data, target, cv=10,\n",
    "    return_estimator=True, scoring=\"accuracy\"\n",
    ")\n",
    "cv_results_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the most important feature seen by the logistic regression?\n",
    "\n",
    "You can use a boxplot to compare the absolute values of the coefficients while\n",
    "also visualizing the variability induced by the cross-validation resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_8572\\1306798407.py:9: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(abs_coefficients, labels=data.columns)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "coefficients = np.array([est.named_steps[\"logisticregression\"].coef_[0] for est in cv_results_num[\"estimator\"]])\n",
    "abs_coefficients = np.abs(coefficients)\n",
    "\n",
    "plt.boxplot(abs_coefficients, labels=data.columns)\n",
    "plt.ylabel(\"Absolute value of coefficients\")\n",
    "plt.title(\"Feature importance across CV folds\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now work with **both numerical and categorical features**. You can\n",
    "reload the Adult Census dataset with the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_census = pd.read_csv(\"./datasets/adult-census.csv\")\n",
    "target = adult_census[\"class\"]\n",
    "data = adult_census.drop(columns=[\"class\", \"education-num\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a predictive model where:\n",
    "- The numerical data must be scaled.\n",
    "- The categorical data must be one-hot encoded, set `min_frequency=0.01` to\n",
    "  group categories concerning less than 1% of the total samples.\n",
    "- The predictor is a `LogisticRegression` with default parameters, except that\n",
    "  you may need to increase the number of `max_iter`, which is 100 by default.\n",
    "\n",
    "Use the same 10-fold cross-validation strategy with `return_estimator=True` as\n",
    "above to evaluate the full pipeline, including the feature scaling and encoding\n",
    "preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:927: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 916, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 317, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 409, in _score\n",
      "    y_pred = method_caller(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 96, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 745, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1099, in transform\n",
      "    Xs = self._call_func_on_transformers(\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 901, in _call_func_on_transformers\n",
      "    return Parallel(n_jobs=self.n_jobs)(jobs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 91, in __call__\n",
      "    return super().__call__(iterable_with_config_and_warning_filters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\joblib\\parallel.py\", line 1986, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\joblib\\parallel.py\", line 1914, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 184, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1464, in _transform_one\n",
      "    res = transformer.transform(X, **params.transform)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1051, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\hp\\Desktop\\bootcamp\\week-3\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 220, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories [' Holand-Netherlands'] in column 7 during transform\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.18193436, 1.03747225, 1.09949613, 1.00533056, 1.06029391,\n",
       "        0.92758536, 0.84352422, 0.9901588 , 0.97765827, 0.87280607]),\n",
       " 'score_time': array([0.04726696, 0.03121114, 0.02440929, 0.02978706, 0.03079295,\n",
       "        0.02038789, 0.02663803, 0.0312438 , 0.02838731, 0.01427627]),\n",
       " 'estimator': [Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                    OneHotEncoder(min_frequency=0.01,\n",
       "                                                                  sparse_output=False),\n",
       "                                                    ['workclass', 'education',\n",
       "                                                     'marital-status',\n",
       "                                                     'occupation', 'relationship',\n",
       "                                                     'race', 'sex',\n",
       "                                                     'native-country']),\n",
       "                                                   ('scaler', StandardScaler(),\n",
       "                                                    ['age', 'capital-gain',\n",
       "                                                     'capital-loss',\n",
       "                                                     'hours-per-week'])])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=200))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                    OneHotEncoder(min_frequency=0.01,\n",
       "                                                                  sparse_output=False),\n",
       "                                                    ['workclass', 'education',\n",
       "                                                     'marital-status',\n",
       "                                                     'occupation', 'relationship',\n",
       "                                                     'race', 'sex',\n",
       "                                                     'native-country']),\n",
       "                                                   ('scaler', StandardScaler(),\n",
       "                                                    ['age', 'capital-gain',\n",
       "                                                     'capital-loss',\n",
       "                                                     'hours-per-week'])])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=200))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                    OneHotEncoder(min_frequency=0.01,\n",
       "                                                                  sparse_output=False),\n",
       "                                                    ['workclass', 'education',\n",
       "                                                     'marital-status',\n",
       "                                                     'occupation', 'relationship',\n",
       "                                                     'race', 'sex',\n",
       "                                                     'native-country']),\n",
       "                                                   ('scaler', StandardScaler(),\n",
       "                                                    ['age', 'capital-gain',\n",
       "                                                     'capital-loss',\n",
       "                                                     'hours-per-week'])])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=200))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                    OneHotEncoder(min_frequency=0.01,\n",
       "                                                                  sparse_output=False),\n",
       "                                                    ['workclass', 'education',\n",
       "                                                     'marital-status',\n",
       "                                                     'occupation', 'relationship',\n",
       "                                                     'race', 'sex',\n",
       "                                                     'native-country']),\n",
       "                                                   ('scaler', StandardScaler(),\n",
       "                                                    ['age', 'capital-gain',\n",
       "                                                     'capital-loss',\n",
       "                                                     'hours-per-week'])])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=200))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                    OneHotEncoder(min_frequency=0.01,\n",
       "                                                                  sparse_output=False),\n",
       "                                                    ['workclass', 'education',\n",
       "                                                     'marital-status',\n",
       "                                                     'occupation', 'relationship',\n",
       "                                                     'race', 'sex',\n",
       "                                                     'native-country']),\n",
       "                                                   ('scaler', StandardScaler(),\n",
       "                                                    ['age', 'capital-gain',\n",
       "                                                     'capital-loss',\n",
       "                                                     'hours-per-week'])])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=200))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                    OneHotEncoder(min_frequency=0.01,\n",
       "                                                                  sparse_output=False),\n",
       "                                                    ['workclass', 'education',\n",
       "                                                     'marital-status',\n",
       "                                                     'occupation', 'relationship',\n",
       "                                                     'race', 'sex',\n",
       "                                                     'native-country']),\n",
       "                                                   ('scaler', StandardScaler(),\n",
       "                                                    ['age', 'capital-gain',\n",
       "                                                     'capital-loss',\n",
       "                                                     'hours-per-week'])])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=200))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                    OneHotEncoder(min_frequency=0.01,\n",
       "                                                                  sparse_output=False),\n",
       "                                                    ['workclass', 'education',\n",
       "                                                     'marital-status',\n",
       "                                                     'occupation', 'relationship',\n",
       "                                                     'race', 'sex',\n",
       "                                                     'native-country']),\n",
       "                                                   ('scaler', StandardScaler(),\n",
       "                                                    ['age', 'capital-gain',\n",
       "                                                     'capital-loss',\n",
       "                                                     'hours-per-week'])])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=200))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                    OneHotEncoder(min_frequency=0.01,\n",
       "                                                                  sparse_output=False),\n",
       "                                                    ['workclass', 'education',\n",
       "                                                     'marital-status',\n",
       "                                                     'occupation', 'relationship',\n",
       "                                                     'race', 'sex',\n",
       "                                                     'native-country']),\n",
       "                                                   ('scaler', StandardScaler(),\n",
       "                                                    ['age', 'capital-gain',\n",
       "                                                     'capital-loss',\n",
       "                                                     'hours-per-week'])])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=200))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                    OneHotEncoder(min_frequency=0.01,\n",
       "                                                                  sparse_output=False),\n",
       "                                                    ['workclass', 'education',\n",
       "                                                     'marital-status',\n",
       "                                                     'occupation', 'relationship',\n",
       "                                                     'race', 'sex',\n",
       "                                                     'native-country']),\n",
       "                                                   ('scaler', StandardScaler(),\n",
       "                                                    ['age', 'capital-gain',\n",
       "                                                     'capital-loss',\n",
       "                                                     'hours-per-week'])])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=200))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                    OneHotEncoder(min_frequency=0.01,\n",
       "                                                                  sparse_output=False),\n",
       "                                                    ['workclass', 'education',\n",
       "                                                     'marital-status',\n",
       "                                                     'occupation', 'relationship',\n",
       "                                                     'race', 'sex',\n",
       "                                                     'native-country']),\n",
       "                                                   ('scaler', StandardScaler(),\n",
       "                                                    ['age', 'capital-gain',\n",
       "                                                     'capital-loss',\n",
       "                                                     'hours-per-week'])])),\n",
       "                  ('logisticregression', LogisticRegression(max_iter=200))])],\n",
       " 'test_score': array([0.85281474, 0.85056295, 0.84971335, 0.8474611 , 0.84807535,\n",
       "        0.84684685, 0.85565111,        nan, 0.85872236, 0.8515561 ])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_columns = data.select_dtypes(include=\"object\").columns.tolist()\n",
    "numerical_columns = data.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"onehotencoder\", OneHotEncoder(min_frequency=0.01, sparse_output=False), categorical_columns),\n",
    "    (\"scaler\", StandardScaler(), numerical_columns)\n",
    "])\n",
    "\n",
    "full_pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    LogisticRegression(max_iter=200)\n",
    ")\n",
    "\n",
    "cv_results_full = cross_validate(\n",
    "    full_pipeline, data, target, cv=10,\n",
    "    return_estimator=True, scoring=\"accuracy\"\n",
    ")\n",
    "cv_results_full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the cross-validation test scores of both models fold-to-fold,\n",
    "count the number of times the model using both numerical and categorical\n",
    "features has a better test score than the model using only numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here.\n",
    "count_better = sum(cv_results_full[\"test_score\"] > cv_results_num[\"test_score\"])\n",
    "count_better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following questions, you can copy and paste the following snippet to\n",
    "get the feature names from the column transformer here named `preprocessor`.\n",
    "\n",
    "```python\n",
    "preprocessor.fit(data)\n",
    "feature_names = (\n",
    "    preprocessor.named_transformers_[\"onehotencoder\"].get_feature_names_out(\n",
    "        categorical_columns\n",
    "    )\n",
    ").tolist()\n",
    "feature_names += numerical_columns\n",
    "feature_names\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass_ ?',\n",
       " 'workclass_ Federal-gov',\n",
       " 'workclass_ Local-gov',\n",
       " 'workclass_ Private',\n",
       " 'workclass_ Self-emp-inc',\n",
       " 'workclass_ Self-emp-not-inc',\n",
       " 'workclass_ State-gov',\n",
       " 'workclass_infrequent_sklearn',\n",
       " 'education_ 10th',\n",
       " 'education_ 11th',\n",
       " 'education_ 12th',\n",
       " 'education_ 5th-6th',\n",
       " 'education_ 7th-8th',\n",
       " 'education_ 9th',\n",
       " 'education_ Assoc-acdm',\n",
       " 'education_ Assoc-voc',\n",
       " 'education_ Bachelors',\n",
       " 'education_ Doctorate',\n",
       " 'education_ HS-grad',\n",
       " 'education_ Masters',\n",
       " 'education_ Prof-school',\n",
       " 'education_ Some-college',\n",
       " 'education_infrequent_sklearn',\n",
       " 'marital-status_ Divorced',\n",
       " 'marital-status_ Married-civ-spouse',\n",
       " 'marital-status_ Married-spouse-absent',\n",
       " 'marital-status_ Never-married',\n",
       " 'marital-status_ Separated',\n",
       " 'marital-status_ Widowed',\n",
       " 'marital-status_infrequent_sklearn',\n",
       " 'occupation_ ?',\n",
       " 'occupation_ Adm-clerical',\n",
       " 'occupation_ Craft-repair',\n",
       " 'occupation_ Exec-managerial',\n",
       " 'occupation_ Farming-fishing',\n",
       " 'occupation_ Handlers-cleaners',\n",
       " 'occupation_ Machine-op-inspct',\n",
       " 'occupation_ Other-service',\n",
       " 'occupation_ Prof-specialty',\n",
       " 'occupation_ Protective-serv',\n",
       " 'occupation_ Sales',\n",
       " 'occupation_ Tech-support',\n",
       " 'occupation_ Transport-moving',\n",
       " 'occupation_infrequent_sklearn',\n",
       " 'relationship_ Husband',\n",
       " 'relationship_ Not-in-family',\n",
       " 'relationship_ Other-relative',\n",
       " 'relationship_ Own-child',\n",
       " 'relationship_ Unmarried',\n",
       " 'relationship_ Wife',\n",
       " 'race_ Asian-Pac-Islander',\n",
       " 'race_ Black',\n",
       " 'race_ White',\n",
       " 'race_infrequent_sklearn',\n",
       " 'sex_ Female',\n",
       " 'sex_ Male',\n",
       " 'native-country_ ?',\n",
       " 'native-country_ Mexico',\n",
       " 'native-country_ United-States',\n",
       " 'native-country_infrequent_sklearn',\n",
       " 'age',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here.\n",
    "preprocessor.fit(data)\n",
    "feature_names = (\n",
    "    preprocessor.named_transformers_[\"onehotencoder\"].get_feature_names_out(categorical_columns)\n",
    ").tolist()\n",
    "feature_names += numerical_columns\n",
    "feature_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are as many feature names as coefficients in the last step\n",
    "of your predictive pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following pairs of features is most impacting the predictions of\n",
    "the logistic regression classifier based on the absolute magnitude of its\n",
    "coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>capital-gain</td>\n",
       "      <td>2.343352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>education_ Doctorate</td>\n",
       "      <td>1.826529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>education_ Prof-school</td>\n",
       "      <td>1.789503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>education_infrequent_sklearn</td>\n",
       "      <td>1.738830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>marital-status_ Married-civ-spouse</td>\n",
       "      <td>1.487255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>education_ 7th-8th</td>\n",
       "      <td>1.372850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>education_ Masters</td>\n",
       "      <td>1.290095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>education_ 9th</td>\n",
       "      <td>1.206267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>education_ 5th-6th</td>\n",
       "      <td>1.181268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>marital-status_ Never-married</td>\n",
       "      <td>1.105761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature  importance\n",
       "61                        capital-gain    2.343352\n",
       "17                education_ Doctorate    1.826529\n",
       "20              education_ Prof-school    1.789503\n",
       "22        education_infrequent_sklearn    1.738830\n",
       "24  marital-status_ Married-civ-spouse    1.487255\n",
       "12                  education_ 7th-8th    1.372850\n",
       "19                  education_ Masters    1.290095\n",
       "13                      education_ 9th    1.206267\n",
       "11                  education_ 5th-6th    1.181268\n",
       "26       marital-status_ Never-married    1.105761"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here.\n",
    "coefficients_full = np.array([est.named_steps[\"logisticregression\"].coef_[0] for est in cv_results_full[\"estimator\"]])\n",
    "abs_coeff_full = np.abs(coefficients_full)\n",
    "mean_abs_coeff = abs_coeff_full.mean(axis=0)\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": mean_abs_coeff\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "feature_importance_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a similar pipeline consisting of the same preprocessor as above,\n",
    "followed by a `PolynomialFeatures` and a logistic regression with `C=0.01` and\n",
    "enough `max_iter`. Set `degree=2` and `interaction_only=True` to the feature\n",
    "engineering step. Remember not to include a \"bias\" feature to avoid\n",
    "introducing a redundancy with the intercept of the subsequent logistic\n",
    "regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([12.94801736, 11.53689098, 12.32091355, 12.10715294, 12.87012148,\n",
       "        13.16725016, 13.28628731, 11.32401919, 12.85706449, 10.79749632]),\n",
       " 'score_time': array([0.13479996, 0.13073778, 0.14776969, 0.18055487, 0.13786459,\n",
       "        0.14482784, 0.13094449, 0.1419642 , 0.14971089, 0.14315367]),\n",
       " 'test_score': array([0.85383828, 0.85383828, 0.8527846 , 0.85298935, 0.84930385,\n",
       "        0.8503276 , 0.85462735, 0.8523751 , 0.85565111, 0.85176085])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "numerical_columns = data.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_columns = data.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"onehotencoder\", OneHotEncoder(min_frequency=0.01, sparse_output=False, handle_unknown=\"ignore\"), categorical_columns),\n",
    "    (\"scaler\", StandardScaler(), numerical_columns)\n",
    "])\n",
    "\n",
    "\n",
    "interaction_pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    PolynomialFeatures(degree=2, interaction_only=True, include_bias=False),\n",
    "    LogisticRegression(C=0.01, max_iter=500)\n",
    ")\n",
    "\n",
    "\n",
    "cv_results_interaction = cross_validate(\n",
    "    interaction_pipeline, data, target, cv=10,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "cv_results_interaction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same 10-fold cross-validation strategy as above to evaluate this\n",
    "pipeline with interactions. In this case there is no need to return the\n",
    "estimator, as the number of features generated by the `PolynomialFeatures` step\n",
    "is much too large to be able to visually explore the learned coefficients of the\n",
    "final classifier.\n",
    "\n",
    "By comparing the cross-validation test scores of both models fold-to-fold,\n",
    "count the number of times the model using multiplicative interactions and both\n",
    "numerical and categorical features has a better test score than the model\n",
    "without interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "week-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
