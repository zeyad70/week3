{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Exercise M7.01\n",
    "\n",
    "In this exercise we will define dummy classification baselines and use them as\n",
    "reference to assess the relative predictive performance of a given model of\n",
    "interest.\n",
    "\n",
    "We illustrate those baselines with the help of the Adult Census dataset, using\n",
    "only the numerical features for the sake of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"./datasets/adult-census-numeric-all.csv\")\n",
    "data, target = adult_census.drop(columns=\"class\"), adult_census[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a `ShuffleSplit` cross-validation strategy taking half of the\n",
    "samples as a testing at each round. Let us use 10 cross-validation rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(\n",
    "    n_splits=10,\n",
    "    test_size=0.5,\n",
    "    random_state=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a machine learning pipeline composed of a transformer to\n",
    "standardize the data followed by a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cross-validation (test) scores for the classifier on this dataset.\n",
    "Store the results pandas Series as we did in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.815937\n",
       "1    0.813849\n",
       "2    0.815036\n",
       "3    0.815569\n",
       "4    0.810982\n",
       "5    0.814831\n",
       "6    0.813112\n",
       "7    0.810368\n",
       "8    0.812375\n",
       "9    0.816306\n",
       "Name: Logistic Regression, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "\n",
    "cv_results_logistic = cross_validate(\n",
    "    logistic_pipeline,\n",
    "    data,\n",
    "    target,\n",
    "    cv=cv,\n",
    "    scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "scores_logistic = pd.Series(\n",
    "    cv_results_logistic[\"test_score\"],\n",
    "    name=\"Logistic Regression\"\n",
    ")\n",
    "\n",
    "scores_logistic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the cross-validation scores of a dummy classifier that constantly\n",
    "predicts the most frequent class observed the training set. Please refer to\n",
    "the online documentation for the [sklearn.dummy.DummyClassifier\n",
    "](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)\n",
    "class.\n",
    "\n",
    "Store the results in a second pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we collected the results from the baseline and the model, concatenate\n",
    "the test scores as columns a single pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, plot the histogram of the cross-validation test scores for both models\n",
    "with the help of [pandas built-in plotting\n",
    "function](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html#histograms).\n",
    "\n",
    "What conclusions do you draw from the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the `strategy` of the dummy classifier to `\"stratified\"`, compute the\n",
    "results. Similarly compute scores for `strategy=\"uniform\"` and then the  plot\n",
    "the distribution together with the other results.\n",
    "\n",
    "Are those new baselines better than the previous one? Why is this the case?\n",
    "\n",
    "Please refer to the scikit-learn documentation on\n",
    "[sklearn.dummy.DummyClassifier](\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)\n",
    "to find out about the meaning of the `\"stratified\"` and `\"uniform\"`\n",
    "strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "week-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
